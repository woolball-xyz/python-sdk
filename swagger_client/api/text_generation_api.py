# coding: utf-8

"""
    Woolball AI Network API

    **Transform idle browsers into a powerful distributed AI inference network**  For detailed examples and model lists, visit our [GitHub repository](https://github.com/woolball-xyz/woolball-server).  # noqa: E501

    OpenAPI spec version: v1
    
    Generated by: https://github.com/swagger-api/swagger-codegen.git
"""

from __future__ import absolute_import

import re  # noqa: F401

# python 2 and python 3 compatibility library
import six

from swagger_client.api_client import ApiClient


class TextGenerationApi(object):
    """NOTE: This class is auto generated by the swagger code generator program.

    Do not edit the class manually.
    Ref: https://github.com/swagger-api/swagger-codegen
    """

    def __init__(self, api_client=None):
        if api_client is None:
            api_client = ApiClient()
        self.api_client = api_client

    def text_generation(self, provider, model, input, top_k, top_p, temperature, repetition_penalty, dtype, max_length, max_new_tokens, min_length, min_new_tokens, do_sample, num_beams, no_repeat_ngram_size, context_window_size, sliding_window_size, attention_sink_size, frequency_penalty, presence_penalty, bos_token_id, max_tokens, random_seed, **kwargs):  # noqa: E501
        """Text Generation - Multi-Provider  # noqa: E501

        Generate text using multiple AI providers (Transformers.js, WebLLM, MediaPipe). Use the 'provider' field to specify which AI provider to use for text generation.  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.text_generation(provider, model, input, top_k, top_p, temperature, repetition_penalty, dtype, max_length, max_new_tokens, min_length, min_new_tokens, do_sample, num_beams, no_repeat_ngram_size, context_window_size, sliding_window_size, attention_sink_size, frequency_penalty, presence_penalty, bos_token_id, max_tokens, random_seed, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param str provider: (required)
        :param str model: (required)
        :param str input: (required)
        :param int top_k: (required)
        :param float top_p: (required)
        :param float temperature: (required)
        :param float repetition_penalty: (required)
        :param str dtype: (required)
        :param int max_length: (required)
        :param int max_new_tokens: (required)
        :param int min_length: (required)
        :param int min_new_tokens: (required)
        :param bool do_sample: (required)
        :param int num_beams: (required)
        :param int no_repeat_ngram_size: (required)
        :param int context_window_size: (required)
        :param int sliding_window_size: (required)
        :param int attention_sink_size: (required)
        :param float frequency_penalty: (required)
        :param float presence_penalty: (required)
        :param int bos_token_id: (required)
        :param int max_tokens: (required)
        :param int random_seed: (required)
        :return: TextGenerationResponse
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('async_req'):
            return self.text_generation_with_http_info(provider, model, input, top_k, top_p, temperature, repetition_penalty, dtype, max_length, max_new_tokens, min_length, min_new_tokens, do_sample, num_beams, no_repeat_ngram_size, context_window_size, sliding_window_size, attention_sink_size, frequency_penalty, presence_penalty, bos_token_id, max_tokens, random_seed, **kwargs)  # noqa: E501
        else:
            (data) = self.text_generation_with_http_info(provider, model, input, top_k, top_p, temperature, repetition_penalty, dtype, max_length, max_new_tokens, min_length, min_new_tokens, do_sample, num_beams, no_repeat_ngram_size, context_window_size, sliding_window_size, attention_sink_size, frequency_penalty, presence_penalty, bos_token_id, max_tokens, random_seed, **kwargs)  # noqa: E501
            return data

    def text_generation_with_http_info(self, provider, model, input, top_k, top_p, temperature, repetition_penalty, dtype, max_length, max_new_tokens, min_length, min_new_tokens, do_sample, num_beams, no_repeat_ngram_size, context_window_size, sliding_window_size, attention_sink_size, frequency_penalty, presence_penalty, bos_token_id, max_tokens, random_seed, **kwargs):  # noqa: E501
        """Text Generation - Multi-Provider  # noqa: E501

        Generate text using multiple AI providers (Transformers.js, WebLLM, MediaPipe). Use the 'provider' field to specify which AI provider to use for text generation.  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.text_generation_with_http_info(provider, model, input, top_k, top_p, temperature, repetition_penalty, dtype, max_length, max_new_tokens, min_length, min_new_tokens, do_sample, num_beams, no_repeat_ngram_size, context_window_size, sliding_window_size, attention_sink_size, frequency_penalty, presence_penalty, bos_token_id, max_tokens, random_seed, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param str provider: (required)
        :param str model: (required)
        :param str input: (required)
        :param int top_k: (required)
        :param float top_p: (required)
        :param float temperature: (required)
        :param float repetition_penalty: (required)
        :param str dtype: (required)
        :param int max_length: (required)
        :param int max_new_tokens: (required)
        :param int min_length: (required)
        :param int min_new_tokens: (required)
        :param bool do_sample: (required)
        :param int num_beams: (required)
        :param int no_repeat_ngram_size: (required)
        :param int context_window_size: (required)
        :param int sliding_window_size: (required)
        :param int attention_sink_size: (required)
        :param float frequency_penalty: (required)
        :param float presence_penalty: (required)
        :param int bos_token_id: (required)
        :param int max_tokens: (required)
        :param int random_seed: (required)
        :return: TextGenerationResponse
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['provider', 'model', 'input', 'top_k', 'top_p', 'temperature', 'repetition_penalty', 'dtype', 'max_length', 'max_new_tokens', 'min_length', 'min_new_tokens', 'do_sample', 'num_beams', 'no_repeat_ngram_size', 'context_window_size', 'sliding_window_size', 'attention_sink_size', 'frequency_penalty', 'presence_penalty', 'bos_token_id', 'max_tokens', 'random_seed']  # noqa: E501
        all_params.append('async_req')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in six.iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method text_generation" % key
                )
            params[key] = val
        del params['kwargs']
        # verify the required parameter 'provider' is set
        if ('provider' not in params or
                params['provider'] is None):
            raise ValueError("Missing the required parameter `provider` when calling `text_generation`")  # noqa: E501
        # verify the required parameter 'model' is set
        if ('model' not in params or
                params['model'] is None):
            raise ValueError("Missing the required parameter `model` when calling `text_generation`")  # noqa: E501
        # verify the required parameter 'input' is set
        if ('input' not in params or
                params['input'] is None):
            raise ValueError("Missing the required parameter `input` when calling `text_generation`")  # noqa: E501
        # verify the required parameter 'top_k' is set
        if ('top_k' not in params or
                params['top_k'] is None):
            raise ValueError("Missing the required parameter `top_k` when calling `text_generation`")  # noqa: E501
        # verify the required parameter 'top_p' is set
        if ('top_p' not in params or
                params['top_p'] is None):
            raise ValueError("Missing the required parameter `top_p` when calling `text_generation`")  # noqa: E501
        # verify the required parameter 'temperature' is set
        if ('temperature' not in params or
                params['temperature'] is None):
            raise ValueError("Missing the required parameter `temperature` when calling `text_generation`")  # noqa: E501
        # verify the required parameter 'repetition_penalty' is set
        if ('repetition_penalty' not in params or
                params['repetition_penalty'] is None):
            raise ValueError("Missing the required parameter `repetition_penalty` when calling `text_generation`")  # noqa: E501
        # verify the required parameter 'dtype' is set
        if ('dtype' not in params or
                params['dtype'] is None):
            raise ValueError("Missing the required parameter `dtype` when calling `text_generation`")  # noqa: E501
        # verify the required parameter 'max_length' is set
        if ('max_length' not in params or
                params['max_length'] is None):
            raise ValueError("Missing the required parameter `max_length` when calling `text_generation`")  # noqa: E501
        # verify the required parameter 'max_new_tokens' is set
        if ('max_new_tokens' not in params or
                params['max_new_tokens'] is None):
            raise ValueError("Missing the required parameter `max_new_tokens` when calling `text_generation`")  # noqa: E501
        # verify the required parameter 'min_length' is set
        if ('min_length' not in params or
                params['min_length'] is None):
            raise ValueError("Missing the required parameter `min_length` when calling `text_generation`")  # noqa: E501
        # verify the required parameter 'min_new_tokens' is set
        if ('min_new_tokens' not in params or
                params['min_new_tokens'] is None):
            raise ValueError("Missing the required parameter `min_new_tokens` when calling `text_generation`")  # noqa: E501
        # verify the required parameter 'do_sample' is set
        if ('do_sample' not in params or
                params['do_sample'] is None):
            raise ValueError("Missing the required parameter `do_sample` when calling `text_generation`")  # noqa: E501
        # verify the required parameter 'num_beams' is set
        if ('num_beams' not in params or
                params['num_beams'] is None):
            raise ValueError("Missing the required parameter `num_beams` when calling `text_generation`")  # noqa: E501
        # verify the required parameter 'no_repeat_ngram_size' is set
        if ('no_repeat_ngram_size' not in params or
                params['no_repeat_ngram_size'] is None):
            raise ValueError("Missing the required parameter `no_repeat_ngram_size` when calling `text_generation`")  # noqa: E501
        # verify the required parameter 'context_window_size' is set
        if ('context_window_size' not in params or
                params['context_window_size'] is None):
            raise ValueError("Missing the required parameter `context_window_size` when calling `text_generation`")  # noqa: E501
        # verify the required parameter 'sliding_window_size' is set
        if ('sliding_window_size' not in params or
                params['sliding_window_size'] is None):
            raise ValueError("Missing the required parameter `sliding_window_size` when calling `text_generation`")  # noqa: E501
        # verify the required parameter 'attention_sink_size' is set
        if ('attention_sink_size' not in params or
                params['attention_sink_size'] is None):
            raise ValueError("Missing the required parameter `attention_sink_size` when calling `text_generation`")  # noqa: E501
        # verify the required parameter 'frequency_penalty' is set
        if ('frequency_penalty' not in params or
                params['frequency_penalty'] is None):
            raise ValueError("Missing the required parameter `frequency_penalty` when calling `text_generation`")  # noqa: E501
        # verify the required parameter 'presence_penalty' is set
        if ('presence_penalty' not in params or
                params['presence_penalty'] is None):
            raise ValueError("Missing the required parameter `presence_penalty` when calling `text_generation`")  # noqa: E501
        # verify the required parameter 'bos_token_id' is set
        if ('bos_token_id' not in params or
                params['bos_token_id'] is None):
            raise ValueError("Missing the required parameter `bos_token_id` when calling `text_generation`")  # noqa: E501
        # verify the required parameter 'max_tokens' is set
        if ('max_tokens' not in params or
                params['max_tokens'] is None):
            raise ValueError("Missing the required parameter `max_tokens` when calling `text_generation`")  # noqa: E501
        # verify the required parameter 'random_seed' is set
        if ('random_seed' not in params or
                params['random_seed'] is None):
            raise ValueError("Missing the required parameter `random_seed` when calling `text_generation`")  # noqa: E501

        collection_formats = {}

        path_params = {}

        query_params = []

        header_params = {}

        form_params = []
        local_var_files = {}
        if 'provider' in params:
            form_params.append(('provider', params['provider']))  # noqa: E501
        if 'model' in params:
            form_params.append(('model', params['model']))  # noqa: E501
        if 'input' in params:
            form_params.append(('input', params['input']))  # noqa: E501
        if 'top_k' in params:
            form_params.append(('top_k', params['top_k']))  # noqa: E501
        if 'top_p' in params:
            form_params.append(('top_p', params['top_p']))  # noqa: E501
        if 'temperature' in params:
            form_params.append(('temperature', params['temperature']))  # noqa: E501
        if 'repetition_penalty' in params:
            form_params.append(('repetition_penalty', params['repetition_penalty']))  # noqa: E501
        if 'dtype' in params:
            form_params.append(('dtype', params['dtype']))  # noqa: E501
        if 'max_length' in params:
            form_params.append(('max_length', params['max_length']))  # noqa: E501
        if 'max_new_tokens' in params:
            form_params.append(('max_new_tokens', params['max_new_tokens']))  # noqa: E501
        if 'min_length' in params:
            form_params.append(('min_length', params['min_length']))  # noqa: E501
        if 'min_new_tokens' in params:
            form_params.append(('min_new_tokens', params['min_new_tokens']))  # noqa: E501
        if 'do_sample' in params:
            form_params.append(('do_sample', params['do_sample']))  # noqa: E501
        if 'num_beams' in params:
            form_params.append(('num_beams', params['num_beams']))  # noqa: E501
        if 'no_repeat_ngram_size' in params:
            form_params.append(('no_repeat_ngram_size', params['no_repeat_ngram_size']))  # noqa: E501
        if 'context_window_size' in params:
            form_params.append(('context_window_size', params['context_window_size']))  # noqa: E501
        if 'sliding_window_size' in params:
            form_params.append(('sliding_window_size', params['sliding_window_size']))  # noqa: E501
        if 'attention_sink_size' in params:
            form_params.append(('attention_sink_size', params['attention_sink_size']))  # noqa: E501
        if 'frequency_penalty' in params:
            form_params.append(('frequency_penalty', params['frequency_penalty']))  # noqa: E501
        if 'presence_penalty' in params:
            form_params.append(('presence_penalty', params['presence_penalty']))  # noqa: E501
        if 'bos_token_id' in params:
            form_params.append(('bos_token_id', params['bos_token_id']))  # noqa: E501
        if 'max_tokens' in params:
            form_params.append(('max_tokens', params['max_tokens']))  # noqa: E501
        if 'random_seed' in params:
            form_params.append(('random_seed', params['random_seed']))  # noqa: E501

        body_params = None
        # HTTP header `Accept`
        header_params['Accept'] = self.api_client.select_header_accept(
            ['application/json'])  # noqa: E501

        # HTTP header `Content-Type`
        header_params['Content-Type'] = self.api_client.select_header_content_type(  # noqa: E501
            ['multipart/form-data'])  # noqa: E501

        # Authentication setting
        auth_settings = []  # noqa: E501

        return self.api_client.call_api(
            '/api/v1/text-generation', 'POST',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type='TextGenerationResponse',  # noqa: E501
            auth_settings=auth_settings,
            async_req=params.get('async_req'),
            _return_http_data_only=params.get('_return_http_data_only'),
            _preload_content=params.get('_preload_content', True),
            _request_timeout=params.get('_request_timeout'),
            collection_formats=collection_formats)
